---
title: "One Pattern -- PCA"
author: "Lizzy Gibson"
date: "6/09/2020"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    toc_depth: 5
---

```{r setup, include=FALSE}
require("knitr")
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(scipen = 999)
library(R.matlab)
library(tidyverse)
library(gridExtra)
library(Matrix)
library(matconv)
library(patchwork)
library(janitor)
library(ggcorrplot)
library(ggfortify)  
library(factoextra)
library(knitr)
library(haven)
library(rlist)
library(mvtnorm)
library(reshape2)
library(GGally)
library(grDevices)
```

# Log Normal

## Simulate

```{r, scores1, echo=TRUE}
# Simulate independent scores
set.seed(1988)
scores <- exp(rnorm(100))
# summary(scores)
# sd(scores)
```

```{r, score_hist1}
scores %>%
  enframe() %>% 
  ggplot(aes(x = value)) +
  geom_histogram() + 
  theme_minimal()
```

```{r, patterns, echo=TRUE}
# Simulate 1 pattern
pattern <- t(c(1,1,1,1,1,1,0,0,0,0))
```

```{r, times, echo=TRUE}
# Add noise
noise <- matrix(NA, nrow = 100, ncol = 10)
seeds <- 1:10
for (i in 1:length(seeds)) {
  set.seed(seeds[i])
  noise[,i] <- exp(rnorm(100, mean = 0, sd = 1))
}

# Multiply scores by pattern
sim_all <- as_tibble((scores %*% pattern) + noise)
#summary(sim_all)
sim_all[sim_all < 0] <- 0 # non-negative
sim_all <- as_tibble(scale(sim_all, center = FALSE, 
                           scale = apply(sim_all, 2, sd, na.rm = TRUE))) # standardize do not center
#sim_all
```

```{r}
# Create mean vector for un-centering
sim_means_sqrt2 <- apply(sim_all, 2, mean)
```

```{r, scale22}
sim_all %>%
  mutate(id = 1:nrow(.)) %>% 
  gather(key = pop, value = value, -id) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() + facet_wrap(~pop) +
  theme_minimal()

ggcorr(sim_all, method = c("everything", "spearman"), limits = FALSE,
       label = TRUE, label_size = 3, label_alpha = TRUE,
       hjust = 0.85, size = 3, color = "grey50", layout.exp = 1)
```

```{r, neg3}
# Create version with 10% lowest values for each variable as below the LOD
mix_data_lod_10_sqrt2 <- sim_all %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .10), (quantile(V1, probs = .10)/sqrt(2)), V1)) %>% as.matrix()
mix_10_means_sqrt2 <- apply(mix_data_lod_10_sqrt2, 2, mean)

# Create version with 20% lowest values for each variable as below the LOD
mix_data_lod_20_sqrt2 <- sim_all %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .20), (quantile(V1, probs = .20)/sqrt(2)), V1)) %>% as.matrix()
mix_20_means_sqrt2 <- apply(mix_data_lod_20_sqrt2, 2, mean)

# Create version with 30% lowest values for each variable as below the LOD
mix_data_lod_30_sqrt2 <- sim_all %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .30), (quantile(V1, probs = .30)/sqrt(2)), V1)) %>% as.matrix()
mix_30_means_sqrt2 <- apply(mix_data_lod_30_sqrt2, 2, mean)

# Create version with 40% lowest values for each variable as below the LOD
mix_data_lod_40_sqrt2 <- sim_all %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .40), (quantile(V1, probs = .40)/sqrt(2)), V1)) %>% as.matrix()
mix_40_means_sqrt2 <- apply(mix_data_lod_40_sqrt2, 2, mean)

# Create version with 50% lowest values for each variable as below the LOD
mix_data_lod_50_sqrt2 <- sim_all %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .50), (quantile(V1, probs = .50)/sqrt(2)), V1)) %>% as.matrix()
mix_50_means_sqrt2 <- apply(mix_data_lod_50_sqrt2, 2, mean)
```

## PCA

```{r}
mix <- as.matrix(sim_all)

pca_0  <- prcomp(mix)
pca_10 <- prcomp(mix_data_lod_10_sqrt2)
pca_20 <- prcomp(mix_data_lod_20_sqrt2)
pca_30 <- prcomp(mix_data_lod_30_sqrt2)
pca_40 <- prcomp(mix_data_lod_40_sqrt2)
pca_50 <- prcomp(mix_data_lod_50_sqrt2)
```

```{r, pca, echo=TRUE}
# pca_50$sdev
plot(pca_50)
```

### Rotations
```{r}
# cor(pca_0$rotation[,1:3], pca_10$rotation[,1:3])
# cor(pca_0$rotation[,1:3], pca_20$rotation[,1:3])
# cor(pca_0$rotation[,1:3], pca_30$rotation[,1:3])
# cor(pca_0$rotation[,1:3], pca_40$rotation[,1:3])
# cor(pca_0$rotation[,1:3], pca_50$rotation[,1:3])

pca_10$rotation[,4] <- -pca_10$rotation[,4]
pca_50$rotation[,5] <- -pca_50$rotation[,5]

rotation_norm <- as_tibble(cbind(`0%` = norm((pca_0$rotation[,1:3] - pca_0$rotation[,1:3]), type = "F")/norm((pca_0$rotation[,1:3]), type = "F"),
      `10%` = norm((pca_0$rotation[,1:3] - pca_10$rotation[,1:3]), type = "F")/norm((pca_0$rotation[,1:3]), type = "F"),
      `20%` = norm((pca_0$rotation[,1:3] - pca_20$rotation[,1:3]), type = "F")/norm((pca_0$rotation[,1:3]), type = "F"),
      `30%` = norm((pca_0$rotation[,1:3] - pca_30$rotation[,1:3]), type = "F")/norm((pca_0$rotation[,1:3]), type = "F"),
      `40%` = norm((pca_0$rotation[,1:3] - pca_40$rotation[,1:3]), type = "F")/norm((pca_0$rotation[,1:3]), type = "F"),
      `50%` = norm((pca_0$rotation[,1:3] - pca_50$rotation[,1:3]), type = "F")/norm((pca_0$rotation[,1:3]), type = "F"))) %>%
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Right Vectors")
```

### Scores
```{r}
pca_10$x[,4] <- -pca_10$x[,4]
pca_50$x[,5] <- -pca_50$x[,5]

score_norm <- as_tibble(cbind(`0%` = norm((pca_0$x[,1:3] - pca_0$x[,1:3]), type = "F")/norm((pca_0$x[,1:3]), type = "F"),
      `10%` = norm((pca_0$x[,1:3] - pca_10$x[,1:3]), type = "F")/norm((pca_0$x[,1:3]), type = "F"),
      `20%` = norm((pca_0$x[,1:3] - pca_20$x[,1:3]), type = "F")/norm((pca_0$x[,1:3]), type = "F"),
      `30%` = norm((pca_0$x[,1:3] - pca_30$x[,1:3]), type = "F")/norm((pca_0$x[,1:3]), type = "F"),
      `40%` = norm((pca_0$x[,1:3] - pca_40$x[,1:3]), type = "F")/norm((pca_0$x[,1:3]), type = "F"),
      `50%` = norm((pca_0$x[,1:3] - pca_50$x[,1:3]), type = "F")/norm((pca_0$x[,1:3]), type = "F"))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Left Vectors")
```

### Singular Values
```{r}
norm_vec <- function(x) sqrt(sum(x^2))

sdev_norm <- as_tibble(cbind(`0%` = norm_vec(pca_0$sdev[1:3] - pca_0$sdev[1:3])/norm_vec(pca_0$sdev[1:3]),
      `10%` = norm_vec(pca_0$sdev[1:3] - pca_10$sdev[1:3])/norm_vec(pca_0$sdev[1:3]),
      `20%` = norm_vec(pca_0$sdev[1:3] - pca_20$sdev[1:3])/norm_vec(pca_0$sdev[1:3]),
      `30%` = norm_vec(pca_0$sdev[1:3] - pca_30$sdev[1:3])/norm_vec(pca_0$sdev[1:3]),
      `40%` = norm_vec(pca_0$sdev[1:3] - pca_40$sdev[1:3])/norm_vec(pca_0$sdev[1:3]),
      `50%` = norm_vec(pca_0$sdev[1:3] - pca_50$sdev[1:3])/norm_vec(pca_0$sdev[1:3]))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Singular Values")
```

#### Viz

```{r, fig.align = "center"}
rbind(rotation_norm, score_norm, sdev_norm) %>% ggplot(aes(x = Percent, y = norm, group = Metric)) + 
  geom_point(aes(color = Metric)) + geom_path(aes(color = Metric)) + theme_bw() +
  labs(x = "Percent Below LOD", y = "norm(difference) / norm(lod0)",
       title = "Relative Error in PCA")
```

### Variance Explained

```{r}
PCA_0 <- pca_0$sdev^2/sum(pca_0$sdev^2) *100
PCA_50 <- pca_50$sdev^2/sum(pca_50$sdev^2) *100

round(cbind(Component = 1:10, PCA_0, PCA_50), 4) %>% kable()
```

### PCA Pred Values

```{r}
# prcomp centers, does not scale
# need to UNCENTER predictions to compare
# REMOVE SV

rep.row<-function(x,n){
  matrix(rep(x,each=n),nrow=n)
}

pca_pred_0  <- pca_0$x[,1:3] %*% t(pca_0$rotation)[1:3,] + rep.row(sim_means_sqrt2, 100)
pca_pred_10 <- pca_10$x[,1:3] %*% t(pca_10$rotation)[1:3,] + rep.row(mix_10_means_sqrt2, 100)
pca_pred_20 <- pca_20$x[,1:3] %*% t(pca_20$rotation)[1:3,] + rep.row(mix_20_means_sqrt2, 100)
pca_pred_30 <- pca_30$x[,1:3] %*% t(pca_30$rotation)[1:3,] + rep.row(mix_30_means_sqrt2, 100)
pca_pred_40 <- pca_40$x[,1:3] %*% t(pca_40$rotation)[1:3,] + rep.row(mix_40_means_sqrt2, 100)
pca_pred_50 <- pca_50$x[,1:3] %*% t(pca_50$rotation)[1:3,] + rep.row(mix_50_means_sqrt2, 100)

# mix[1,]
# pca_pred_0[1,]
# mix_data_lod_50_sqrt2[1,]
# pca_pred_50[1,]
```

```{r, tp_lod1}
pred_pca <- as_tibble(cbind(Simulated = mix[,1],
                          `0%` = pca_pred_0[,1],
                          `10%` = pca_pred_10[,1],
                          `20%` = pca_pred_20[,1],
                          `30%` = pca_pred_30[,1],
                          `40%` = pca_pred_40[,1],
                          `50%` = pca_pred_50[,1],
          id = 1:100)) %>% gather(key = Percent, value = Predicted, -Simulated, -id) %>% 
  mutate(LOD = c(rep(0, 100), rep(quantile(mix[,1], .10), 100),
                 rep(quantile(mix[,1], .20), 100),
                 rep(quantile(mix[,1], .30), 100),
                 rep(quantile(mix[,1], .40), 100),
                 rep(quantile(mix[,1], .50), 100)))

# pred_pca
```

#### Viz
```{r, fig.align="center"}
pred_pca %>% 
  ggplot(aes(x = Simulated, y = Predicted)) + 
  geom_hline(yintercept = 0, color = 'grey', linetype = 'dashed') +
  geom_rect(aes(xmin = 0, xmax = LOD, ymin = 0, ymax = LOD),
                   fill = "pink", alpha = 0.03) +
  geom_abline(intercept = 0, slope = 1, color = 'grey', linetype = 'dashed') +
  geom_point(aes(color = Percent)) +
  facet_wrap(~Percent) +
  theme_bw() + theme(legend.position = "none") +
  labs(title= "Log Normal Simulated v. Predicted Values for POP V1")
```

```{r, fig.align="center"}
pred_pca %>% 
  filter(Simulated <= LOD) %>% 
  ggplot(aes(x = Simulated, y = Predicted)) + 
  geom_hline(yintercept = 0, color = 'grey', linetype = 'dashed') +
  geom_rect(aes(xmin = 0, xmax = LOD, ymin = 0, ymax = LOD),
                   fill = "pink", alpha = 0.03) +
  geom_abline(intercept = 0, slope = 1, color = 'grey', linetype = 'dashed') +
  geom_point(aes(color = Percent)) +
  facet_wrap(~Percent) +
  theme_bw() + theme(legend.position = "none") +
  labs(title= "Log Normal Simulated v. Predicted Values for POP V1 <LOD")
```

```{r}
pred_pca %>% 
  gather(key = Data, value = Value, -id, -Percent, -LOD) %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram(aes(fill = Data, color = Data), alpha = 0.25) + 
  theme_bw() +
  facet_wrap(.~Percent) +
  labs(y = "Count",
       title = "Log Normal Simulated Data + PCA Solution") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
pred_pca %>% 
  filter(Simulated <= LOD) %>% 
  gather(key = Data, value = Value, -id, -Percent, -LOD) %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram(aes(fill = Data, color = Data), alpha = 0.25) + 
  theme_bw() +
  facet_wrap(.~Percent) +
  labs(y = "Count",
       title = "Log Normal Simulated Data + PCA Solution <LOD") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1))
```


## Relative Error

### V1

```{r}
### <LOD
pred_pca %>%
  filter(Simulated < LOD) %>% 
  mutate(l2 = (Simulated - Predicted)^2,
         l1 = abs(Simulated - Predicted)) %>%
  group_by(Percent) %>% 
           summarise(Fro = sqrt(sum(l2))/sqrt(sum(Simulated^2)),
                     l1 = sqrt(sum(l1))/sqrt(sum(Simulated)),
                     linf = max(l1)/max(Simulated))

### Overall
pred_pca %>%
  mutate(l2 = (Simulated - Predicted)^2,
         l1 = abs(Simulated - Predicted)) %>%
  group_by(Percent) %>% 
           summarise(Fro = sqrt(sum(l2))/sqrt(sum(Simulated^2)),
                     l1 = sqrt(sum(l1))/sqrt(sum(Simulated)),
                     linf = max(l1)/max(Simulated))

### >LOD
pred_pca %>%
  filter(Simulated >= LOD) %>% 
  mutate(l2 = (Simulated - Predicted)^2,
         l1 = abs(Simulated - Predicted)) %>%
  group_by(Percent) %>% 
           summarise(Fro = sqrt(sum(l2))/sqrt(sum(Simulated^2)),
                     l1 = sqrt(sum(l1))/sqrt(sum(Simulated)),
                     linf = max(l1)/max(Simulated))
```

### All

```{r}
pred_sim <- sim_all %>% 
  mutate(id = 1:100) %>% 
  pivot_longer(cols = V1:V10,
               names_to = "Variable",
               values_to = "Simulated")

add_lods <- as_tibble(rbind(c("0%",0), 
      c("10%", quantile(mix[,1], .10)), 
      c("20%", quantile(mix[,1], .20)),
      c("30%", quantile(mix[,1], .30)), 
      c("40%", quantile(mix[,1], .40)),
      c("50%", quantile(mix[,1], .50)))) %>% rename(Percent = 1, LOD = 2) %>% 
  mutate(LOD = as.numeric(LOD),
         Variable = "V1")

pred_all <- pca_pred_0 %>% as_tibble() %>% mutate(Percent = "0%") %>% 
  rbind(., pca_pred_10 %>% as_tibble() %>% mutate(Percent = "10%")) %>% 
  rbind(., pca_pred_20 %>% as_tibble() %>% mutate(Percent = "20%")) %>% 
  rbind(., pca_pred_30 %>% as_tibble() %>% mutate(Percent = "30%")) %>% 
  rbind(., pca_pred_40 %>% as_tibble() %>% mutate(Percent = "40%")) %>% 
  rbind(., pca_pred_50 %>% as_tibble() %>% mutate(Percent = "50%")) %>%
  mutate(id = rep(1:100, 6)) %>% 
  pivot_longer(cols = V1:V10,
               names_to = "Variable",
               values_to = "Predicted") %>% 
  left_join(., pred_sim, by = c("id", "Variable")) %>% 
  left_join(., add_lods, by = c("Percent", "Variable")) %>% 
  replace_na(list(LOD = 0))

# check
# pred_all %>% filter(Variable == "V1") %>% slice(550:560)
# pred_pca[550:560,]
```

```{r}
### <LOD are only V1

### Overall
pred_all %>%
  mutate(l2 = (Simulated - Predicted)^2,
         l1 = abs(Simulated - Predicted)) %>%
  group_by(Percent) %>% 
           summarise(Fro = sqrt(sum(l2))/sqrt(sum(Simulated^2)),
                     l1 = sqrt(sum(l1))/sqrt(sum(Simulated)),
                     linf = max(l1)/max(Simulated))

### >LOD
pred_all %>%
  filter(Simulated >= LOD) %>% 
  mutate(l2 = (Simulated - Predicted)^2,
         l1 = abs(Simulated - Predicted)) %>%
  group_by(Percent) %>% 
           summarise(Fro = sqrt(sum(l2))/sqrt(sum(Simulated^2)),
                     l1 = sqrt(sum(l1))/sqrt(sum(Simulated)),
                     linf = max(l1)/max(Simulated))
```

# Normal

## Simulate

```{r, scores, echo=TRUE}
# Simulate independent scores
set.seed(1988)
scores_n <- (rnorm(100))
# summary(scores_n)
# sd(scores_n)
```

```{r, score_hist}
scores_n %>%
  enframe() %>% 
  ggplot(aes(x = value)) +
  geom_histogram() + 
  theme_minimal()
```

Same Patterns!

```{r, times1, echo=TRUE}
# Add noise
noise_n <- matrix(NA, nrow = 100, ncol = 10)
#seeds <- 1:10
for (i in 1:length(seeds)) {
  set.seed(seeds[i])
  noise_n[,i] <- (rnorm(100, mean = 0, sd = 1))
}

# Multiply scores by pattern
sim_n <- as_tibble((scores_n %*% pattern) + noise_n)
# summary(sim_n)
#sim_n[sim_n < 0] <- 0 # allow negative
sim_n <- as_tibble(scale(sim_n, center = FALSE, 
                           scale = apply(sim_n, 2, sd, na.rm = TRUE))) # standardize do not center
# sim_n
```

```{r}
# Create mean vector for un-centering
sim_means_n <- apply(sim_n, 2, mean)
```

```{r, scale2}
sim_n %>%
  mutate(id = 1:nrow(.)) %>% 
  gather(key = pop, value = value, -id) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() + facet_wrap(~pop) +
  theme_minimal()

ggcorr(sim_n, method = c("everything", "spearman"), limits = FALSE,
       label = TRUE, label_size = 3, label_alpha = TRUE,
       hjust = 0.85, size = 3, color = "grey50", layout.exp = 1)
```

```{r, neg1}
# Create version with 10% lowest values for each variable as below the LOD
mix_data_lod_10_n <- sim_n %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .10), (quantile(V1, probs = .10)/sqrt(2)), V1)) %>% as.matrix()
mix_10_means_n <- apply(mix_data_lod_10_n, 2, mean)

# Create version with 20% lowest values for each variable as below the LOD
mix_data_lod_20_n <- sim_n %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .20), (quantile(V1, probs = .20)/sqrt(2)), V1)) %>% as.matrix()
mix_20_means_n <- apply(mix_data_lod_20_n, 2, mean)

# Create version with 30% lowest values for each variable as below the LOD
mix_data_lod_30_n <- sim_n %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .30), (quantile(V1, probs = .30)/sqrt(2)), V1)) %>% as.matrix()
mix_30_means_n <- apply(mix_data_lod_30_n, 2, mean)

# Create version with 40% lowest values for each variable as below the LOD
mix_data_lod_40_n <- sim_n %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .40), (quantile(V1, probs = .40)/sqrt(2)), V1)) %>% as.matrix()
mix_40_means_n <- apply(mix_data_lod_40_n, 2, mean)

# Create version with 50% lowest values for each variable as below the LOD
mix_data_lod_50_n <- sim_n %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .50), (quantile(V1, probs = .50)/sqrt(2)), V1)) %>% as.matrix()
mix_50_means_n <- apply(mix_data_lod_50_n, 2, mean)
```

## PCA 

```{r}
# prcomp centers, does not scale
mix_n <- as.matrix(sim_n)

pca_0_n  <- prcomp(mix_n)
pca_10_n <- prcomp(mix_data_lod_10_n)
pca_20_n <- prcomp(mix_data_lod_20_n)
pca_30_n <- prcomp(mix_data_lod_30_n)
pca_40_n <- prcomp(mix_data_lod_40_n)
pca_50_n <- prcomp(mix_data_lod_50_n)
```

```{r, pca2, echo=TRUE}
# pca_50_n$sdev
plot(pca_50_n)
```

### Rotations
```{r, rotations_n}
# cor(pca_0_n$rotation[,1:3], pca_10_n$rotation[,1:3])
# cor(pca_0_n$rotation[,1:3], pca_20_n$rotation[,1:3])
# cor(pca_0_n$rotation[,1:3], pca_30_n$rotation[,1:3])
# cor(pca_0_n$rotation[,1:3], pca_40_n$rotation[,1:3])
# cor(pca_0_n$rotation[,1:3], pca_50_n$rotation[,1:3])

pca_10_n$rotation[,3] <- -pca_10_n$rotation[,3]
pca_40_n$rotation[,3] <- -pca_40_n$rotation[,3]
pca_20_n$rotation[,3] <- -pca_20_n$rotation[,3]
pca_30_n$rotation[,3] <- -pca_30_n$rotation[,3]
pca_50_n$rotation[,1:2] <- -pca_50_n$rotation[,2]

rotation_norm_n <- as_tibble(cbind(`0%` = norm((pca_0_n$rotation[,1:3] - pca_0_n$rotation[,1:3]), type = "F")/norm((pca_0_n$rotation[,1:3]), type = "F"),
      `10%` = norm((pca_0_n$rotation[,1:3] - pca_10_n$rotation[,1:3]), type = "F")/norm((pca_0_n$rotation[,1:3]), type = "F"),
      `20%` = norm((pca_0_n$rotation[,1:3] - pca_20_n$rotation[,1:3]), type = "F")/norm((pca_0_n$rotation[,1:3]), type = "F"),
      `30%` = norm((pca_0_n$rotation[,1:3] - pca_30_n$rotation[,1:3]), type = "F")/norm((pca_0_n$rotation[,1:3]), type = "F"),
      `40%` = norm((pca_0_n$rotation[,1:3] - pca_40_n$rotation[,1:3]), type = "F")/norm((pca_0_n$rotation[,1:3]), type = "F"),
      `50%` = norm((pca_0_n$rotation[,1:3] - pca_50_n$rotation[,1:3]), type = "F")/norm((pca_0_n$rotation[,1:3]), type = "F"))) %>%
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Right Vectors")

# rotation_norm_n
```

### Scores
```{r, scores_n}
pca_40_n$x[,3] <- -pca_40_n$x[,3]
pca_20_n$x[,3] <- -pca_20_n$x[,3]
pca_30_n$x[,3] <- -pca_30_n$x[,3]
pca_50_n$x[,1:2] <- -pca_50_n$x[,2]
pca_10_n$x[,3] <- -pca_10_n$x[,3]

score_norm_n <- as_tibble(cbind(`0%` = norm((pca_0_n$x[,1:3] - pca_0_n$x[,1:3]), type = "F")/norm((pca_0_n$x[,1:3]), type = "F"),
      `10%` = norm((pca_0_n$x[,1:3] - pca_10_n$x[,1:3]), type = "F")/norm((pca_0_n$x[,1:3]), type = "F"),
      `20%` = norm((pca_0_n$x[,1:3] - pca_20_n$x[,1:3]), type = "F")/norm((pca_0_n$x[,1:3]), type = "F"),
      `30%` = norm((pca_0_n$x[,1:3] - pca_30_n$x[,1:3]), type = "F")/norm((pca_0_n$x[,1:3]), type = "F"),
      `40%` = norm((pca_0_n$x[,1:3] - pca_40_n$x[,1:3]), type = "F")/norm((pca_0_n$x[,1:3]), type = "F"),
      `50%` = norm((pca_0_n$x[,1:3] - pca_50_n$x[,1:3]), type = "F")/norm((pca_0_n$x[,1:3]), type = "F"))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Left Vectors")

# score_norm_n
```

### Singular Values
```{r, sv_n}
sdev_norm_n <- as_tibble(cbind(`0%` = norm_vec(pca_0_n$sdev[1:3] - pca_0_n$sdev[1:3])/norm_vec(pca_0_n$sdev[1:3]),
      `10%` = norm_vec(pca_0_n$sdev[1:3] - pca_10_n$sdev[1:3])/norm_vec(pca_0_n$sdev[1:3]),
      `20%` = norm_vec(pca_0_n$sdev[1:3] - pca_20_n$sdev[1:3])/norm_vec(pca_0_n$sdev[1:3]),
      `30%` = norm_vec(pca_0_n$sdev[1:3] - pca_30_n$sdev[1:3])/norm_vec(pca_0_n$sdev[1:3]),
      `40%` = norm_vec(pca_0_n$sdev[1:3] - pca_40_n$sdev[1:3])/norm_vec(pca_0_n$sdev[1:3]),
      `50%` = norm_vec(pca_0_n$sdev[1:3] - pca_50_n$sdev[1:3])/norm_vec(pca_0_n$sdev[1:3]))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Singular Values")

# sdev_norm_n
```

#### Viz

```{r, fig.align = "center"}
rbind(rotation_norm_n, score_norm_n, sdev_norm_n) %>% ggplot(aes(x = Percent, y = norm, group = Metric)) + 
  geom_point(aes(color = Metric)) + geom_path(aes(color = Metric)) + theme_bw() +
  labs(x = "Percent Below LOD", y = "norm(difference) / norm(lod0)",
       title = "Relative Error in PCA")
```

### Variance Explained

```{r}
PCA_0_n <- pca_0_n$sdev^2/sum(pca_0_n$sdev^2) *100
PCA_50_n <- pca_50_n$sdev^2/sum(pca_50_n$sdev^2) *100

round(cbind(Component = 1:10, PCA_0_n, PCA_50_n), 4) %>% kable()
```

### PCA Pred Values

```{r}
# prcomp centers, does not scale
# need to UNCENTER predictions to compare
# REMOVE SV

pca_pred_0_n  <- pca_0_n$x[,1:3] %*% t(pca_0_n$rotation)[1:3,] + rep.row(sim_means_n, 100)
pca_pred_10_n <- pca_10_n$x[,1:3] %*% t(pca_10_n$rotation)[1:3,] + rep.row(mix_10_means_n, 100)
pca_pred_20_n <- pca_20_n$x[,1:3] %*% t(pca_20_n$rotation)[1:3,] + rep.row(mix_20_means_n, 100)
pca_pred_30_n <- pca_30_n$x[,1:3] %*% t(pca_30_n$rotation)[1:3,] + rep.row(mix_30_means_n, 100)
pca_pred_40_n <- pca_40_n$x[,1:3] %*% t(pca_40_n$rotation)[1:3,] + rep.row(mix_40_means_n, 100)
pca_pred_50_n <- pca_50_n$x[,1:3] %*% t(pca_50_n$rotation)[1:3,] + rep.row(mix_50_means_n, 100)

# mix_n[1,]
# pca_pred_0_n[1,]

# mix_data_lod_50_n[1,]
# pca_pred_50_n[1,]
```

```{r, tp_lod2}
pred_pca_n <- as_tibble(cbind(Simulated = mix_n[,1],
                          `0%` = pca_pred_0_n[,1],
                          `10%` = pca_pred_10_n[,1],
                          `20%` = pca_pred_20_n[,1],
                          `30%` = pca_pred_30_n[,1],
                          `40%` = pca_pred_40_n[,1],
                          `50%` = pca_pred_50_n[,1],
          id = 1:100)) %>% gather(key = Percent, value = Predicted, -Simulated, -id) %>% 
  mutate(LOD = c(rep(quantile(mix_n[,1], .0), 100), rep(quantile(mix_n[,1], .10), 100),
                 rep(quantile(mix_n[,1], .20), 100),
                 rep(quantile(mix_n[,1], .30), 100),
                 rep(quantile(mix_n[,1], .40), 100),
                 rep(quantile(mix_n[,1], .50), 100)))
pred_pca_n
```

```{r}
F_norm_pca_n <- as_tibble(cbind(`0%` = norm((mix_n - pca_pred_0_n), type = "F")/norm((mix_n), type = "F"),
      `10%` = norm((mix_n - pca_pred_10_n), type = "F")/norm((mix_n), type = "F"),
      `20%` = norm((mix_n - pca_pred_20_n), type = "F")/norm((mix_n), type = "F"),
      `30%` = norm((mix_n - pca_pred_30_n), type = "F")/norm((mix_n), type = "F"),
      `40%` = norm((mix_n - pca_pred_40_n), type = "F")/norm((mix_n), type = "F"),
      `50%` = norm((mix_n - pca_pred_50_n), type = "F")/norm((mix_n), type = "F"))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA")

# F_norm_pca_n
```

#### Viz
```{r, fig.align="center"}
pred_pca_n %>% 
  ggplot(aes(x = Simulated, y = Predicted)) + 
  geom_hline(yintercept = 0, color = 'grey', linetype = 'dashed') +
  geom_rect(aes(xmin = -Inf, xmax = LOD, ymin = -Inf, ymax = LOD),
                   fill = "pink", alpha = 0.03) +
  geom_abline(intercept = 0, slope = 1, color = 'grey', linetype = 'dashed') +
  geom_point(aes(color = Percent)) +
  facet_wrap(~Percent) +
  theme_bw() + theme(legend.position = "none") +
  labs(title= "Normal Simulated v. Predicted Values for POP V1")
```

```{r, fig.align="center"}
pred_pca_n %>% 
  filter(Simulated <= LOD) %>% 
  ggplot(aes(x = Simulated, y = Predicted)) + 
  geom_hline(yintercept = 0, color = 'grey', linetype = 'dashed') +
  geom_rect(aes(xmin = -Inf, xmax = LOD, ymin = -Inf, ymax = LOD),
                   fill = "pink", alpha = 0.03) +
  geom_abline(intercept = 0, slope = 1, color = 'grey', linetype = 'dashed') +
  geom_point(aes(color = Percent)) +
  facet_wrap(~Percent) +
  theme_bw() + theme(legend.position = "none") +
  labs(title= "Normal Simulated v. Predicted Values for POP V1 <LOD")
```

```{r}
pred_pca_n %>% 
  gather(key = Data, value = Value, -id, -Percent, -LOD) %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram(aes(fill = Data, color = Data), alpha = 0.25) + 
  theme_bw() +
  facet_wrap(.~Percent) +
  labs(y = "Count",
       title = "Normal Simulated Data + PCA Solution") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
pred_pca_n %>% 
  filter(Simulated <= LOD) %>% 
  gather(key = Data, value = Value, -id, -Percent, -LOD) %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram(aes(fill = Data, color = Data), alpha = 0.25) + 
  theme_bw() +
  facet_wrap(.~Percent) +
  labs(y = "Count",
       title = "Normal Simulated Data + PCA Solution <LOD") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1))
```

# Non-Negative Normal

## Simulate

Same Scores!

Same Patterns!

Same Noise!

```{r, times2, echo=TRUE}
# Multiply scores by pattern
sim_n_nn <- as_tibble((scores_n %*% pattern) + 2 + noise_n)
# summary(sim_n_nn)
sim_n_nn[sim_n_nn < 0] <- 0 # NON negative
sim_n_nn <- as_tibble(scale(sim_n_nn, center = FALSE, 
                         scale = apply(sim_n_nn, 2, sd, na.rm = TRUE))) # standardize do not center
# sim_n_nn
```

```{r}
# Create mean vector for un-centering
sim_means_n_nn <- apply(sim_n_nn, 2, mean)
```

```{r, scale3}
sim_n_nn %>%
  mutate(id = 1:nrow(.)) %>% 
  gather(key = pop, value = value, -id) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() + facet_wrap(~pop) +
  theme_minimal()

ggcorr(sim_n_nn, method = c("everything", "spearman"), limits = FALSE,
       label = TRUE, label_size = 3, label_alpha = TRUE,
       hjust = 0.85, size = 3, color = "grey50", layout.exp = 1)
```

```{r, neg}
# Create version with 10% lowest values for each variable as below the LOD
mix_data_lod_10_n_nn <- sim_n_nn %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .10), (quantile(V1, probs = .10)/sqrt(2)), V1)) %>% as.matrix()
mix_10_means_n_nn <- apply(mix_data_lod_10_n_nn, 2, mean)

# Create version with 20% lowest values for each variable as below the LOD
mix_data_lod_20_n_nn <- sim_n_nn %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .20), (quantile(V1, probs = .20)/sqrt(2)), V1)) %>% as.matrix()
mix_20_means_n_nn <- apply(mix_data_lod_20_n_nn, 2, mean)

# Create version with 30% lowest values for each variable as below the LOD
mix_data_lod_30_n_nn <- sim_n_nn %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .30), (quantile(V1, probs = .30)/sqrt(2)), V1)) %>% as.matrix()
mix_30_means_n_nn <- apply(mix_data_lod_30_n_nn, 2, mean)

# Create version with 40% lowest values for each variable as below the LOD
mix_data_lod_40_n_nn <- sim_n_nn %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .40), (quantile(V1, probs = .40)/sqrt(2)), V1)) %>% as.matrix()
mix_40_means_n_nn <- apply(mix_data_lod_40_n_nn, 2, mean)

# Create version with 50% lowest values for each variable as below the LOD
mix_data_lod_50_n_nn <- sim_n_nn %>% 
  mutate(V1 = ifelse(V1 < quantile(V1, probs = .50), (quantile(V1, probs = .50)/sqrt(2)), V1)) %>% as.matrix()
mix_50_means_n_nn <- apply(mix_data_lod_50_n_nn, 2, mean)
```

## PCA

```{r}
# prcomp centers, does not scale

mix_n_nn <- as.matrix(sim_n_nn)

pca_0_n_nn  <- prcomp(mix_n_nn)
pca_10_n_nn <- prcomp(mix_data_lod_10_n_nn)
pca_20_n_nn <- prcomp(mix_data_lod_20_n_nn)
pca_30_n_nn <- prcomp(mix_data_lod_30_n_nn)
pca_40_n_nn <- prcomp(mix_data_lod_40_n_nn)
pca_50_n_nn <- prcomp(mix_data_lod_50_n_nn)

# norm(mix_n_nn, "F")
```

```{r, pca3, echo=TRUE}
# pca_50_n_nn$sdev
plot(pca_50_n_nn)
```

### Rotations
```{r}
# cor(pca_0_n_nn$rotation[,1:3], pca_10_n_nn$rotation[,1:3])
# cor(pca_0_n_nn$rotation[,1:3], pca_20_n_nn$rotation[,1:3])
# cor(pca_0_n_nn$rotation[,1:3], pca_30_n_nn$rotation[,1:3])
# cor(pca_0_n_nn$rotation[,1:3], pca_40_n_nn$rotation[,1:3])
# cor(pca_0_n_nn$rotation[,1:3], pca_50_n_nn$rotation[,1:3])

pca_10_n_nn$rotation[,3] <- -pca_10_n_nn$rotation[,3]
pca_40_n_nn$rotation[,3] <- -pca_40_n_nn$rotation[,3]
pca_20_n_nn$rotation[,3] <- -pca_20_n_nn$rotation[,3]
pca_30_n_nn$rotation[,3] <- -pca_30_n_nn$rotation[,3]
pca_50_n_nn$rotation[,3] <- -pca_50_n_nn$rotation[,3]

rotation_norm_n_nn <- as_tibble(cbind(`0%` = norm((pca_0_n_nn$rotation[,1:3] - pca_0_n_nn$rotation[,1:3]), type = "F")/
                                        norm((pca_0_n_nn$rotation[,1:3]), type = "F"),
                                   `10%` = norm((pca_0_n_nn$rotation[,1:3] - pca_10_n_nn$rotation[,1:3]), type = "F")/
                                     norm((pca_0_n_nn$rotation[,1:3]), type = "F"),
                                   `20%` = norm((pca_0_n_nn$rotation[,1:3] - pca_20_n_nn$rotation[,1:3]), type = "F")/
                                     norm((pca_0_n_nn$rotation[,1:3]), type = "F"),
                                   `30%` = norm((pca_0_n_nn$rotation[,1:3] - pca_30_n_nn$rotation[,1:3]), type = "F")/
                                     norm((pca_0_n_nn$rotation[,1:3]), type = "F"),
                                   `40%` = norm((pca_0_n_nn$rotation[,1:3] - pca_40_n_nn$rotation[,1:3]), type = "F")/
                                     norm((pca_0_n_nn$rotation[,1:3]), type = "F"),
                                   `50%` = norm((pca_0_n_nn$rotation[,1:3] - pca_50_n_nn$rotation[,1:3]), type = "F")/
                                     norm((pca_0_n_nn$rotation[,1:3]), type = "F"))) %>%
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Right Vectors")

# rotation_norm_n_nn
```

### Scores
```{r}
pca_40_n_nn$x[,3] <- -pca_40_n_nn$x[,3]
pca_20_n_nn$x[,3] <- -pca_20_n_nn$x[,3]
pca_30_n_nn$x[,3] <- -pca_30_n_nn$x[,3]
pca_50_n_nn$x[,3] <- -pca_50_n_nn$x[,3]
pca_10_n_nn$x[,3] <- -pca_10_n_nn$x[,3]

score_norm_n_nn <- as_tibble(cbind(`0%` = norm((pca_0_n_nn$x[,1:3] - pca_0_n_nn$x[,1:3]), type = "F")/
                                     norm((pca_0_n_nn$x[,1:3]), type = "F"),
                                `10%` = norm((pca_0_n_nn$x[,1:3] - pca_10_n_nn$x[,1:3]), type = "F")/
                                  norm((pca_0_n_nn$x[,1:3]), type = "F"),
                                `20%` = norm((pca_0_n_nn$x[,1:3] - pca_20_n_nn$x[,1:3]), type = "F")/
                                  norm((pca_0_n_nn$x[,1:3]), type = "F"),
                                `30%` = norm((pca_0_n_nn$x[,1:3] - pca_30_n_nn$x[,1:3]), type = "F")/
                                  norm((pca_0_n_nn$x[,1:3]), type = "F"),
                                `40%` = norm((pca_0_n_nn$x[,1:3] - pca_40_n_nn$x[,1:3]), type = "F")/
                                  norm((pca_0_n_nn$x[,1:3]), type = "F"),
                                `50%` = norm((pca_0_n_nn$x[,1:3] - pca_50_n_nn$x[,1:3]), type = "F")/
                                  norm((pca_0_n_nn$x[,1:3]), type = "F"))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Left Vectors")

# score_norm_n_nn
```

### Singular Values
```{r}
sdev_norm_n_nn <- as_tibble(cbind(`0%` = norm_vec(pca_0_n_nn$sdev[1:3] - pca_0_n_nn$sdev[1:3])/norm_vec(pca_0_n_nn$sdev[1:3]),
                               `10%` = norm_vec(pca_0_n_nn$sdev[1:3] - pca_10_n_nn$sdev[1:3])/norm_vec(pca_0_n_nn$sdev[1:3]),
                               `20%` = norm_vec(pca_0_n_nn$sdev[1:3] - pca_20_n_nn$sdev[1:3])/norm_vec(pca_0_n_nn$sdev[1:3]),
                               `30%` = norm_vec(pca_0_n_nn$sdev[1:3] - pca_30_n_nn$sdev[1:3])/norm_vec(pca_0_n_nn$sdev[1:3]),
                               `40%` = norm_vec(pca_0_n_nn$sdev[1:3] - pca_40_n_nn$sdev[1:3])/norm_vec(pca_0_n_nn$sdev[1:3]),
                               `50%` = norm_vec(pca_0_n_nn$sdev[1:3] - pca_50_n_nn$sdev[1:3])/norm_vec(pca_0_n_nn$sdev[1:3]))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA",
         Metric = "Singular Values")

# sdev_norm_n_nn
```

#### Viz

```{r, fig.align = "center"}
rbind(rotation_norm_n_nn, score_norm_n_nn, sdev_norm_n_nn) %>% ggplot(aes(x = Percent, y = norm, group = Metric)) + 
  geom_point(aes(color = Metric)) + geom_path(aes(color = Metric)) + theme_bw() +
  labs(x = "Percent Below LOD", y = "norm(difference) / norm(lod0)",
       title = "Relative Error in PCA")
```

### Variance Explained

```{r}
PCA_0_n_nn <- pca_0_n_nn$sdev^2/sum(pca_0_n_nn$sdev^2) *100
PCA_50_n_nn <- pca_50_n_nn$sdev^2/sum(pca_50_n_nn$sdev^2) *100

round(cbind(Component = 1:10, PCA_0_n_nn, PCA_50_n_nn), 4) %>% kable()
```

### PCA Pred Values

```{r}
# prcomp centers, does not scale
# need to UNCENTER predictions to compare
# REMOVE SV

pca_pred_0_n_nn  <- pca_0_n_nn$x[,1:3] %*% t(pca_0_n_nn$rotation)[1:3,] + rep.row(sim_means_n_nn, 100)
pca_pred_10_n_nn <- pca_10_n_nn$x[,1:3] %*% t(pca_10_n_nn$rotation)[1:3,] + rep.row(mix_10_means_n_nn, 100)
pca_pred_20_n_nn <- pca_20_n_nn$x[,1:3] %*% t(pca_20_n_nn$rotation)[1:3,] + rep.row(mix_20_means_n_nn, 100)
pca_pred_30_n_nn <- pca_30_n_nn$x[,1:3] %*% t(pca_30_n_nn$rotation)[1:3,] + rep.row(mix_30_means_n_nn, 100)
pca_pred_40_n_nn <- pca_40_n_nn$x[,1:3] %*% t(pca_40_n_nn$rotation)[1:3,] + rep.row(mix_40_means_n_nn, 100)
pca_pred_50_n_nn <- pca_50_n_nn$x[,1:3] %*% t(pca_50_n_nn$rotation)[1:3,] + rep.row(mix_50_means_n_nn, 100)

# mix_n_nn[1,]
# pca_pred_0_n_nn[1,]
# 
# mix_data_lod_50_n_nn[1,]
# pca_pred_50_n_nn[1,]
```

```{r, tp_lod}
pred_pca_n_nn <- as_tibble(cbind(Simulated = mix_n_nn[,1],
                              `0%` = pca_pred_0_n_nn[,1],
                              `10%` = pca_pred_10_n_nn[,1],
                              `20%` = pca_pred_20_n_nn[,1],
                              `30%` = pca_pred_30_n_nn[,1],
                              `40%` = pca_pred_40_n_nn[,1],
                              `50%` = pca_pred_50_n_nn[,1],
                              id = 1:100)) %>% gather(key = Percent, value = Predicted, -Simulated, -id) %>% 
  mutate(LOD = c(rep(quantile(mix_n_nn[,1], .0), 100), rep(quantile(mix_n_nn[,1], .10), 100),
                 rep(quantile(mix_n_nn[,1], .20), 100),
                 rep(quantile(mix_n_nn[,1], .30), 100),
                 rep(quantile(mix_n_nn[,1], .40), 100),
                 rep(quantile(mix_n_nn[,1], .50), 100)))
# pred_pca_n_nn
```

```{r}
F_norm_pca_n_nn <- as_tibble(cbind(`0%` = norm((mix_n_nn - pca_pred_0_n_nn), type = "F")/norm((mix_n_nn), type = "F"),
                                `10%` = norm((mix_n_nn - pca_pred_10_n_nn), type = "F")/norm((mix_n_nn), type = "F"),
                                `20%` = norm((mix_n_nn - pca_pred_20_n_nn), type = "F")/norm((mix_n_nn), type = "F"),
                                `30%` = norm((mix_n_nn - pca_pred_30_n_nn), type = "F")/norm((mix_n_nn), type = "F"),
                                `40%` = norm((mix_n_nn - pca_pred_40_n_nn), type = "F")/norm((mix_n_nn), type = "F"),
                                `50%` = norm((mix_n_nn - pca_pred_50_n_nn), type = "F")/norm((mix_n_nn), type = "F"))) %>% 
  gather(Percent, norm) %>% 
  mutate(Method = "PCA")

# F_norm_pca_n_nn
```

#### Viz
```{r, fig.align="center"}
pred_pca_n_nn %>% 
  ggplot(aes(x = Simulated, y = Predicted)) + 
  geom_hline(yintercept = 0, color = 'grey', linetype = 'dashed') +
  geom_rect(aes(xmin = -Inf, xmax = LOD, ymin = -Inf, ymax = LOD),
            fill = "pink", alpha = 0.03) +
  geom_abline(intercept = 0, slope = 1, color = 'grey', linetype = 'dashed') +
  geom_point(aes(color = Percent)) +
  facet_wrap(~Percent) +
  theme_bw() + theme(legend.position = "none") +
  labs(title= "Non-Negative Normal Simulated v. Predicted Values for POP V1")
```

```{r, fig.align="center"}
pred_pca_n_nn %>% 
  filter(Simulated <= LOD) %>% 
  ggplot(aes(x = Simulated, y = Predicted)) + 
  geom_hline(yintercept = 0, color = 'grey', linetype = 'dashed') +
  geom_rect(aes(xmin = -Inf, xmax = LOD, ymin = -Inf, ymax = LOD),
            fill = "pink", alpha = 0.03) +
  geom_abline(intercept = 0, slope = 1, color = 'grey', linetype = 'dashed') +
  geom_point(aes(color = Percent)) +
  facet_wrap(~Percent) +
  theme_bw() + theme(legend.position = "none") +
  labs(title= "Non-Negative Normal Simulated v. Predicted Values for POP V1 <LOD")
```

```{r}
pred_pca_n_nn %>% 
  gather(key = Data, value = Value, -id, -Percent, -LOD) %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram(aes(fill = Data, color = Data), alpha = 0.25) + 
  theme_bw() +
  facet_wrap(.~Percent) +
  labs(y = "Count",
       title = "Non-Negative Normal Simulated Data + PCA Solution") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
pred_pca_n_nn %>% 
  filter(Simulated <= LOD) %>% 
  gather(key = Data, value = Value, -id, -Percent, -LOD) %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram(aes(fill = Data, color = Data), alpha = 0.25) + 
  theme_bw() +
  facet_wrap(.~Percent) +
  labs(y = "Count",
       title = "Non-Negative Normal Simulated Data + PCA Solution <LOD") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1))
```

