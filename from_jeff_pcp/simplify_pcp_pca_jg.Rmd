---
title: "One Pattern Sims"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    code_folding: hide
---

```{r setup, include=FALSE}
library(tidyverse)
 
knitr::opts_chunk$set(
	echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 8,
  fig.height = 6
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))

source(here::here("from_jeff_pcp/source", "pca_jg.R"))

set.seed(10)
```

## Simulate

```{r, scores}
set.seed(1988)

n = 100

scores <- matrix(exp(rnorm(n)), nrow = n, ncol = 1)
pattern <- t(c(1,1,1,1,1,1,0,0,0,0))

# Add noise
noise <- 
  mvtnorm::rmvnorm(n, mean = rep(0, 10), sigma = diag(.1, 10, 10)) %>% 
  exp()

# Multiply scores by pattern
sim_all <- as_tibble((scores %*% pattern) + noise)
sim_all[sim_all < 0] <- 0 
sim_all <- as_tibble(scale(sim_all, center = FALSE, 
                           scale = apply(sim_all, 2, sd, na.rm = TRUE))) # standardize do not center

sim_all %>%
  mutate(id = 1:nrow(.)) %>% 
  gather(key = pop, value = value, -id) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() + facet_wrap(~pop)

sim_all %>% 
  mutate(subj = row_number()) %>% 
  pivot_longer(
    V1:V10,
    names_to = "chem",
    values_to = "value"
  ) %>% 
  ggplot(aes(x = chem, y = value, group = subj)) +
  geom_line()
```

```{r}
create_lod_mat = function(df, quant) {
  
  df %>%
    mutate(V1 = ifelse(V1 < quantile(V1, probs = quant), -1, V1)) %>% 
    as.matrix()
  
}


create_lod_imp_mat = function(df, quant) {
  
  df = 
    df %>%
    mutate(V1 = ifelse(V1 < quantile(V1, probs = quant), NA, V1))
  
  mod = lm(V1 ~ V2 + V3 + V4 + V5, data = df)
  
  
  df %>%
    modelr::add_predictions(mod) %>% 
    mutate(
      V1 = case_when(
        is.na(V1) ~ pred,
        TRUE      ~ V1
      )) %>% 
    select(-pred) %>% 
    as.matrix()
  
}

create_lod_sqrt2_mat = function(df, quant) {
  
  df %>%
    mutate(V1 = ifelse(
      V1 < quantile(V1, probs = quant), 
      (quantile(V1, probs = quant)/sqrt(2)), V1)) %>%
    as.matrix()

}

create_v1_missing_ind = function(mat) {
  tibble(below_lod = (mat[,1] == -1))
}
```

note to jeff -- constructing a covariance on the LOD'd matrix gives a biased estimate. probably this is because the addition of the measurement error prior to thresholding results in a biased sample? doesn't happen if missingness is random. effect is somewhat mitigated for pairwise complete; unclear whether that's better than complete in terms of reconstruction accuracy or assumptions about data generating mechanism. 

Create observed matrices under a few mechanisms and with differing levels of below LOD. 

```{r, neg}
lod_mat_df = 
  tibble(
    quant = seq(0, .5, by = .1)
  ) %>% 
  mutate(
    lod_mat =     map(quant, ~create_lod_mat(df = sim_all, quant = .x)),
    lod_imp_mat = map(quant, ~create_lod_imp_mat(df = sim_all, quant = .x)),
    lod_sq2_mat = map(quant, ~create_lod_sqrt2_mat(df = sim_all, quant = .x)),
    delta =       map(quant, ~c(quantile(sim_all$V1, probs = .x), rep(0, times = 9))),
    below_lod   = map(lod_mat, create_v1_missing_ind))
```

## Fit

Fit all models to all observed matrices. This is starting to get messy ...

```{r, include = FALSE}
m <- nrow(sim_all)
p <- ncol(sim_all)

lambda_mix <- 1/sqrt(m)
mu_mix <- sqrt(p/(2*log(m*p)))

fit_df = 
  lod_mat_df %>% 
  pivot_longer(
    lod_mat:lod_sq2_mat,
    names_to = "mechanism",
    values_to = "mat"
  ) %>% 
  mutate(
    pca = map(mat, pca_jg),
    pcp = map2(mat, delta, ~pcpr::pcp_lod(.x, lambda_mix, mu_mix, .y)),
  )
```

define a quick function to compute residuals ...

```{r}
col_residual = function(fit, target_mat) {
  
  if (is.matrix(fit)) {
    as_tibble(target_mat - fit) %>% 
      select(resid = V1)
  }
  
  else {
#    as_tibble(target_mat - fit$L - fit$S) %>% 
    as_tibble(target_mat - fit$L ) %>% 
      select(resid = V1)
  }
}
```

## Evaluate

```{r}
target = scores %*% pattern
# target = as.matrix(sim_all)

results_df = 
  fit_df %>% 
  pivot_longer(
    pca:pcp,
    names_to = "method",
    values_to = "fit"
  ) %>% 
  mutate(
    col1_resid = map(fit, col_residual, target_mat = target),
    method = factor(method),
    mechanism = factor(mechanism),
    mechanism = fct_inorder(mechanism)
  ) %>% 
  select(-delta, -mat, -fit) %>% 
  unnest(cols = c(below_lod, col1_resid))
```


```{r}
agg_results = 
  results_df %>% 
  group_by(mechanism, method, quant, below_lod) %>% 
  summarize(
    mean_sq = mean(resid^2)
  )
```

first a table with squared resid values below lod (in column subject to lod)

```{r}
agg_results %>% 
  filter(below_lod == TRUE) %>% 
  select(mechanism, quant, mean_sq) %>% 
  pivot_wider(
    names_from = quant,
    values_from = mean_sq
  ) %>% 
  knitr::kable(digits = 3)
```

second a table with squared resid values above lod (in column subject to lod)

```{r}
agg_results %>% 
  filter(below_lod == FALSE) %>% 
  select(mechanism, quant, mean_sq) %>% 
  pivot_wider(
    names_from = quant,
    values_from = mean_sq
  ) %>% 
  knitr::kable(digits = 3)
```

some notes:

-- what is the right "target" -- the matrix with or without noise?
-- do we care more about pcp fits with or without the sparse matrix? 
-- when noise cranks up, pcp does better than pca -- not too surprising, i think